{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font face=\"times\"><font size=\"6pt\"><p style = 'text-align: center;'> The City University of New York, Queens College\n",
    "\n",
    "<font face=\"times\"><font size=\"6pt\"><p style = 'text-align: center;'><b>Introduction to Computational Social Science</b><br/><br/>\n",
    "\n",
    "<p style = 'text-align: center;'><font face=\"times\"><b>Lesson 06 | KNN and SVM</b><br/><br/>\n",
    "\n",
    "<p style = 'text-align: center;'><font face=\"times\"><b>5 Checkpoints</b><br/><br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# Begin Lesson 06\n",
    "\n",
    "## Supervised Learning In-Depth: \n",
    "\n",
    "### KNN and SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is machine learning, and how does it work?\n",
    "*Source, from the video series: [Introduction to machine learning with scikit-learn](https://github.com/justmarkham/scikit-learn-videos)*\n",
    "\n",
    "![Machine learning](Images/01_robot.png)\n",
    "\n",
    "## Overview\n",
    "\n",
    "- What is machine learning?\n",
    "- What are the two main categories of machine learning?\n",
    "- What are some examples of machine learning?\n",
    "- How does machine learning \"work\"?\n",
    "\n",
    "## What is machine learning?\n",
    "\n",
    "There are a few ways to think about this. For instance, machine learning is in some sense using computers to detect patterns in data. But let's be a more analytical. Here's a definition that we can work through: \"Machine learning is the semi-automated extraction of knowledge from data.\" What does each part of this definition mean?\n",
    "\n",
    "- **Knowledge from data**: Machine learning starts with a question that might be answerable using data\n",
    "- **Automated extraction**: A computer provides the insight\n",
    "- **Semi-automated**: A computer provides the insight, but it also requires many smart decisions by a human\n",
    "\n",
    "You might also wonder how this is different from statistics more generally. There are lots of opinions about this, but we can start and end with a [famous paper](https://projecteuclid.org/download/pdf_1/euclid.ss/1009213726) by Leo Breiman, an equally famous statistician. Breiman suggests that the difference between machine learning and statistics boils down to culture: statistics has historically been more interested in models that can be understood and explained by human beings, while machine learning has more pragmatic goals with its algorithms, aiming not to necessarily be understood, but to produce workable solutions to particular problems.\n",
    "\n",
    "As a result, while you might be able to explain to a friend or a client what an OLS model is doing and what its results mean, you may not be able to do the same thing with certain machine learning approaches. It may be hard to explain how a particular neural network (to take an extreme example) arrived at its results, but it will still make accurate predictions, often noticeably better than those made by an OLS model.\n",
    "\n",
    "## What are the two main categories of machine learning?\n",
    "\n",
    "**Supervised learning**: Making predictions using data\n",
    "    \n",
    "- Example: Is a given email \"spam\" or \"ham\"?\n",
    "- There is an outcome we are trying to predict\n",
    "\n",
    "![Spam filter](Images/01_spam_filter.png)\n",
    "\n",
    "**Unsupervised learning**: Extracting structure from data\n",
    "\n",
    "- Example: Segment grocery store shoppers into clusters that exhibit similar behaviors\n",
    "- There is no \"right answer\"\n",
    "\n",
    "![Clustering](Images/01_clustering.png)\n",
    "\n",
    "## How does (supervised) machine learning \"work\"?\n",
    "\n",
    "High-level steps of supervised learning:\n",
    "\n",
    "1. First, train a **machine learning model** using **labeled data**\n",
    "\n",
    "    - \"Labeled data\" has been labeled with the outcome (i.e. there is a column in the dataframe registering the outcome)\n",
    "    - \"Machine learning model\" learns the relationship between the attributes of the data and its outcome\n",
    "\n",
    "2. Then, make **predictions** on **new data** for which the label is unknown\n",
    "\n",
    "![Supervised learning](Images/01_supervised_learning.png)\n",
    "\n",
    "The primary goal of supervised learning is to build a model that \"generalizes\": It accurately predicts the **future** rather than the **past**!\n",
    "\n",
    "## How does (unsupervised) machine learning \"work\"?\n",
    "\n",
    "Glad you asked! Models will specify how it is that they find structure in a mass of data. The actual process they use, however, varies--sometimes pretty dramatically--from model to model.\n",
    "\n",
    "## Questions about machine learning\n",
    "\n",
    "- How do I choose **which attributes** of my data to include in the model?\n",
    "- How do I choose **which model** to use?\n",
    "- How do I **optimize** this model for best performance?\n",
    "- How do I ensure that I'm building a model that will **generalize** to unseen data?\n",
    "- Can I **estimate** how well my model is likely to perform on unseen data?\n",
    "\n",
    "## Resources\n",
    "\n",
    "- Book: [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) (section 2.1, 14 pages)\n",
    "- Video: [Learning Paradigms](http://work.caltech.edu/library/014.html) (13 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## Using `Scikit-Learn`\n",
    "\n",
    "- What are the benefits and drawbacks of scikit-learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![scikit-learn algorithm map](Images/02_sklearn_algorithms.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefits of `scikit-learn`:\n",
    "\n",
    "- **Consistent interface** to machine learning models\n",
    "- Provides many **tuning parameters** but with **sensible defaults**\n",
    "- Exceptional **documentation**\n",
    "- Rich set of functionality for **companion tasks**\n",
    "- **Active community** for development and support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the end of this notebook you should:\n",
    "\n",
    "- have a qualitative idea of what problem K-Nearest Neighbors (KNN) and Support Vector Machines (SVMs) are trying to solve\n",
    "- understand how decision trees work\n",
    "- understand how multiple decision trees are combined into *Random Forests*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## Exploring Multi-Dimensional Data with Machine Learning\n",
    "\n",
    "First, let's explore one of the most popular machine learning algorithms called K-Nearest Neighbor (KNN). To do so, we'll need to first prep data and explore how we use these data with machine learning algorithims. \n",
    "\n",
    "So, let's import our required modules that we'll be using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our test data using `pandas`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fruits = pd.read_csv('Data/fruit_data_with_colors.txt',sep=\"\\t\")\n",
    "fruits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a mapping from fruit label value to fruit name to make results easier to interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lookup_fruit_name = dict(zip(fruits.fruit_label.unique(), fruits.fruit_name.unique()))   \n",
    "lookup_fruit_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file contains the mass, height, and width of a selection of oranges, lemons and apples. The heights were measured along the core of the fruit. The widths were the widest width perpendicular to the height."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Now, let's examine the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, though, we'll import one last module. We haven't seen the `cm` module from matplotlib yet, but it will help us plot a scatter matrix, which will be useful in a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split our data into our dependent variables (e.g., Y) and our independent variables (e.g., X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = fruits[['height', 'width', 'mass', 'color_score']]\n",
    "y = fruits['fruit_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use the train_test_split `scikit-learn` function to split both the X and y DataFrames into a \"training\" and a \"test\" set. This function will split-off 25% of the data for \"testing\" and the other 75% for \"training.\" This is the default setup.\n",
    "\n",
    "The idea here is important. If we train a model with the full set of data we risk \"overfitting\" it, or teaching it to so perfectly map a particular set of data (including its outliers and anomalies) that it loses sight of more general patterns. In the worst case scenario, overfitting can even make a model *in*effective when applied to data outside of the training set.\n",
    "\n",
    "Because the train_test_split function creates two times the number of dataframes as what you started with, if you want to keep these subsets you need to specify enough objects to store them. So, if we want to split X and y into training and test sets we need four objects to hold those results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "# Checkpoint 1 of 5\n",
    "\n",
    "## Now you try!\n",
    "\n",
    "### Repeat the steps above and create a new set of training and testing data, but calling them:\n",
    "\n",
    "`X_train_chkpt1, X_test_chkpt1, y_train_chkpt1, y_test_chkpt1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting and exploring these data\n",
    "\n",
    "Let's take a look at the training data before we do anything.\n",
    "\n",
    "We're going to make a 3D scatter plot, where the three dimensions will be the \"height,\" \"width,\" and the \"mass\" of the fruit. \n",
    "\n",
    "Let's use the `cm` module to first set it up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmap = cm.get_cmap('gnuplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use pandas (e.g., `pd`) to create a 2D scatter plot, where we plot every independent variable with each other. We will use the `plotting` function, specifically the `scatter_matrix` function. What's great about this function is that we get scatterplots of all independent variables, and we get histograms on its diagonals.  \n",
    "\n",
    "We're going to use the `X_train` `DataFrame`, where the color of the markers (in this case, circles) is the value assigned by the `y_train` `DataFrame`.\n",
    "\n",
    "Let's also pass in `cmap` to the `scatter_matrix` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scatter = pd.scatter_matrix(X_train, #Our independent variables\n",
    "                                     c= y_train, #Color is the group\n",
    "                                     marker = 'o', #Dots\n",
    "                                     s=40, #Size\n",
    "                                     hist_kwds={'bins':15}, #The bin size for the diagonal histograms\n",
    "                                     figsize=(9,9), #Size of the scatterplot\n",
    "                                     cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting higher-dimensional data in 2D is great, but it's hard to interpret. So let's go up the highest dimension that we can really work with: 3D.\n",
    "\n",
    "To do so let's use the Axes3D module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure() #This opens the pipe to the plot, now we'll pass in parameters\n",
    "ax = fig.add_subplot(111, projection = '3d') #We're going to create a 3D plot\n",
    "ax.scatter(X_train['width'], #X-axis\n",
    "           X_train['height'], #Y-axis\n",
    "           X_train['color_score'], #Z-axis\n",
    "           c = y_train, #Color is the training value\n",
    "           marker = 'o', #We'll use dots, represented by the letter \"o\"\n",
    "           s=100) #Size of the dots\n",
    "ax.set_xlabel('width') #This labels the x-axis as \"width\"\n",
    "ax.set_ylabel('height')#This labels the y-axis as \"height\"\n",
    "ax.set_zlabel('color_score') #This labels the z-axis as \"color\"\n",
    "plt.show() #Now plot it by closing out the plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "# K-Nearest Neighbor (KNN)\n",
    "\n",
    "If you play around with this plot (i.e., click and drag it around), you can see that there are some groupings based on these features. \n",
    "\n",
    "To dig a bit deeper, let's use a classifier called the K-Nearest Neighbor (KNN) model. It is a supervised machine learning algorithim, because you are trying to classify a point based on the known classification of other points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, let's focus on the attributes of the fruit. So, instead of looking at the `color_score`, let's look at fruits' `mass`. So, let's re-split our data up into training and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = fruits[['mass', 'width', 'height']]\n",
    "y = fruits['fruit_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the `scikit-learn` module, and import the K-Nearest Neighbor function that's already prepackaged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's set up our KNN model. The only parameter we need to pass in is the number of clusters that we think exist in our data. Don't worry if you think this number is off, we'll discuss that in a minute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train the classifier (fit the estimator) using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall, the test data sets that we set up. Now, let's use them to estimate the accuracy of the classifier on future data. In other words, we constructed the model based on the training data. Now, let's test it and see how well it worked and predicting values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that the accuracy is only 50%. In other words, really no better than chance. (We can fix this later.)\n",
    "\n",
    "First, let's use the trained KNN classifier model to classify new, previously unseen objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First example: a small fruit with mass 20 grams, width 4.3 cm, height 5.5 cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fruit_prediction = knn.predict([[20, 4.3, 5.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what fruit it predicted. Recall the `Dictionary` we made earlier called `lookup_fruit_name`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lookup_fruit_name[fruit_prediction[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second example: a larger, elongated fruit with mass 100g, width 6.3 cm, height 8.5 cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fruit_prediction = knn.predict([[100, 6.3, 8.5]])\n",
    "lookup_fruit_name[fruit_prediction[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "# Checkpoint 2 of 5\n",
    "\n",
    "## Now you try!\n",
    "\n",
    "### Repeat the above KNN model, but instead of using 'mass', 'width', 'height', just use 'mass' and 'height'. Be sure to create new variables:\n",
    "- X_ckpt2 and Y_ckpt2\n",
    "- X_train_chkpt2, X_test_ckpt2, y_train+ckpt2, y_test_ckpt2\n",
    "- knn_chkpt2\n",
    "\n",
    "### Use `K`=5 neighbors, just as before. \n",
    "\n",
    "### Use mass as 100g and height as 8.5 cm. What fruit does your model predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall, we set the model to have 5 neighborhoods. Also, recall how accurate (or inaccurate) our mdoel is. This begs the question: \n",
    "    How sensitive is k-NN classification accuracy to the choice of the `k` parameter. \n",
    "    \n",
    "Let's test our model across a range of `k`s, from 1 to 20. Let's create a `for-loop` and re-run the model for values each value of `k` through 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_range = range(1,20)\n",
    "scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores.append(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the accuracy of the models for each value of `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([0,5,10,15,20]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the higher the value of `K` (i.e., x-axis), the less accurate the model is (y-axis). In fact, beyond `K`=9, the accuracy drops. This is when machine learning becomes more of an art than a science. The number `K` depends on what is meaningful to your research question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Now, let's see how sensitive the KNN classification accuracy is to the train/test split proportion? Recall we used a 75/25 split. \n",
    "\n",
    "Let's create a list `t` of different test propotions (the traing proportions is 1 minus this value), and run a `for-loop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = [0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot this. (Note it will take a few minutes to run.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "for s in t:\n",
    "\n",
    "    scores = [] #List for scores, but reset with each value in the list, t\n",
    "    for i in range(1,1000): #Train for a 1,000 iterations \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1-s)\n",
    "        knn.fit(X_train, y_train)\n",
    "        scores.append(knn.score(X_test, y_test)) #Append scores\n",
    "    plt.plot(s, np.mean(scores), 'bo') #Save the average value of these scores for this value in t\n",
    "\n",
    "plt.xlabel('Training set proportion (%)')\n",
    "plt.ylabel('accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the higher the proportion dedicated to 'training' the better the accuracy. \n",
    "\n",
    "However, as mentioned earlier, this runs the risk of overfitting the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Predictions and Evaluation of a Machine Learning\n",
    "\n",
    "Now that we have a model it is time to use it to get predictions! We can do this simply with the `predict()` method off of our fitted model (Note: this may take some time).\n",
    "\n",
    "Let's revist the fruit data we used earlier. Let's look at `X_test`. \n",
    "\n",
    "Note: Make sure for the checkpoints you didn't accidently use `X_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the prediction values from the `knn` model we ran earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the `y_pred`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this array of 1s and 3s mean? It's the  prediction of each \"fruit.\" We used the KNN to classify fruit based on its features. \n",
    "\n",
    "However, we need to evaluate how good these predictions are. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use SciKit-Learn's built in metrics such as a classification report and confusion matrix to evaluate how well our model performed. \n",
    "\n",
    "The simplest way might be to count the number of matches and mis-matches. But this is not always sufficient.  For example, imagine you have a situation where you'd like to identify a rare class of event from within a large number of background sources (in astronomy, an example of this is finding variable stars from the background of non-varying stars)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this mean?\n",
    "\n",
    "These are ways of taking into account not just the classification results, but the results **relative to the true category**.\n",
    "\n",
    "$$ {\\rm accuracy} \\equiv \\frac{\\rm correct~labels}{\\rm total~samples} $$\n",
    "\n",
    "$$ {\\rm precision} \\equiv \\frac{\\rm true~positives}{\\rm true~positives + false~positives} $$\n",
    "\n",
    "$$ {\\rm recall} \\equiv \\frac{\\rm true~positives}{\\rm true~positives + false~negatives} $$\n",
    "\n",
    "$$ F_1 \\equiv 2 \\frac{\\rm precision \\cdot recall}{\\rm precision + recall} $$\n",
    "\n",
    "The **accuracy**, **precision**, **recall**, and **f1-score** all range from 0 to 1, with 1 being optimal.\n",
    "Here we've used the following definitions:\n",
    "\n",
    "- *True Positives* are those which are labeled ``1`` which are actually ``1``\n",
    "- *False Positives* are those which are labeled ``1`` which are actually ``0``\n",
    "- *True Negatives* are those which are labeled ``0`` which are actually ``0``\n",
    "- *False Negatives* are those which are labeled ``0`` which are actually ``1``\n",
    "\n",
    "\n",
    "Here's a great way to visualize it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Visualizing the F1](Images/11_Precisionrecall.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly compute a summary of these statistics using scikit-learn's provided `classification_report` and `metrics` scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"accuracy:\", metrics.accuracy_score(y_test, predictions))\n",
    "print(\"precision:\", metrics.precision_score(y_test, predictions,average='weighted'))\n",
    "print(\"recall:\", metrics.recall_score(y_test, predictions,average='weighted'))\n",
    "print(\"f1 score:\", metrics.f1_score(y_test, predictions,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that the overall correct classification rate is 26.7% (accuracy). \n",
    "\n",
    "We correctly identify 26.7% of the desired samples (recall), and those that we properly labeled to \"culitvate\" are 7% correct (precision)! Not great. Let's try out some other models.  \n",
    "\n",
    "(Note: the results will vary each time you run the code because the model will be trained on a different sample.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "****\n",
    "\n",
    "# Checkpoint 3 of 5\n",
    "\n",
    "## Now you try!\n",
    "\n",
    "### Using a new set of data on wines from UCI, run a KNN with the values of K=3, 5, and 7. For each value of K, calculate accuracy and precision. \n",
    "\n",
    "### I've set up the data for you below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wine = pd.read_csv('Data/wine_data.csv', \n",
    "                   names = [\"Cultivator\", \n",
    "                            \"Alchol\", \n",
    "                            \"Malic_Acid\", \n",
    "                            \"Ash\", \n",
    "                            \"Alcalinity_of_Ash\", \n",
    "                            \"Magnesium\", \n",
    "                            \"Total_phenols\", \n",
    "                            \"Falvanoids\", \n",
    "                            \"Nonflavanoid_phenols\", \n",
    "                            \"Proanthocyanins\", \n",
    "                            \"Color_intensity\", \n",
    "                            \"Hue\", \n",
    "                            \"OD280\", \n",
    "                            \"Proline\"])\n",
    "\n",
    "X = wine.drop(\"Cultivator\",axis=1)[[\"var1\",\"var2\",\"var3\"]] #Pick three features for the KNN as your X\n",
    "y = wine[\"Cultivator\"] #We'll use \"cultivator\" as your Y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There are many machine learning algorithms available; here we'll go into brief detail on one of the most common and interesting ones: **Support Vector Machines (SVMs)**.\n",
    "\n",
    "As before, we'll start by getting our notebook ready for interactive plotting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines (SVMs) are a powerful supervised learning algorithm used for **classification** or for **regression**. SVMs are a **discriminative** classifier: that is, they draw a boundary between clusters of data.\n",
    "\n",
    "Let's show a quick example of support vector classification. First we need to create a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "X, y = make_blobs(n_samples=50, centers=2,\n",
    "                  random_state=0, cluster_std=0.60)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll fit a Support Vector Machine (SVM) classifier to these points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # \"Support Vector Classifier\"\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better visualize what's happening here, let's create a quick convenience function that will plot SVM decision boundaries for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_svc_decision_function(clf):\n",
    "    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n",
    "    x = np.linspace(plt.xlim()[0], plt.xlim()[1], 30)\n",
    "    y = np.linspace(plt.ylim()[0], plt.ylim()[1], 30)\n",
    "    Y, X = np.meshgrid(y, x)\n",
    "    P = np.zeros_like(X)\n",
    "    for i, xi in enumerate(x):\n",
    "        for j, yj in enumerate(y):\n",
    "            P[i, j] = clf.decision_function([[xi, yj]])\n",
    "    return plt.contour(X, Y, P, \n",
    "                       colors='k',\n",
    "                       levels=[-1, 0, 1],\n",
    "                       linestyles=['--', '-', '--'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50)\n",
    "plot_svc_decision_function(clf);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the dashed lines touch a couple of the points: these points are known as the \"support vectors,\" and are stored in the ``support_vectors_`` attribute of the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50)\n",
    "plot_svc_decision_function(clf)\n",
    "plt.scatter(clf.support_vectors_[:, 0], \n",
    "            clf.support_vectors_[:, 1],\n",
    "            s=200, facecolors='none');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unique thing about SVM is that only the support vectors matter: that is, if you moved any of the other points without letting them cross the decision boundaries, they would have no effect on the classification results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The properties of SVMs make them extremely useful classifiers in practice.\n",
    "\n",
    "Now, let's take a look at another powerful classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "# Bringing It All Together\n",
    "\n",
    "So, let's bring everything we've done in this unit together. We can evaluate the performance of our supervised models in the same way we did for the KNN. \n",
    "\n",
    "We'll use Support Vector Machine (SVM), which, if you recall from last time, tries to map data points in a way that maximizes the spatial gap between the clusters. In two dimensions, this just means drawing a line (or curves) to divide the data points. (Or in three dimensions it means drawing a plane to do the same task. And so on.)\n",
    "\n",
    "First, let's import some modules that we'll be using. (We already did this earlier, but I want to include all of the code you'll need to run a proper model from start to finish in one place.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first read in the data. Let's use the wine fraud data from UC, Irvine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wine = pd.read_csv('Data/wine_data.csv', \n",
    "                   names = [\"Cultivator\", \n",
    "                            \"Alchol\", \n",
    "                            \"Malic_Acid\", \n",
    "                            \"Ash\", \n",
    "                            \"Alcalinity_of_Ash\", \n",
    "                            \"Magnesium\", \n",
    "                            \"Total_phenols\", \n",
    "                            \"Falvanoids\", \n",
    "                            \"Nonflavanoid_phenols\", \n",
    "                            \"Proanthocyanins\", \n",
    "                            \"Color_intensity\", \n",
    "                            \"Hue\", \n",
    "                            \"OD280\", \n",
    "                            \"Proline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = wine.drop(\"Cultivator\",axis=1) #Let's use all of these features in the SVM as our X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = wine[\"Cultivator\"] #We'll again use \"cultivator\" as our Y. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the modules we'll be needing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our previous discussion of the importance of splitting data into a *training set* and a *testing set*: we'll be extending that here. \n",
    "\n",
    "Now, let's estimate an SVM model, by first splitting our data into a training and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0) #Split the data\n",
    "clf = SVC().fit(X_train, y_train) #Fit the training data to the model\n",
    "y_pred = clf.predict(X_test) #Now use the test-data (X_Test) to see how well it does "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem here is that we might not care how well we can classify the **background**, but might instead be concerned with successfully pulling-out an uncontaminated set of **foreground** sources.  We can get at this by computing statistics such as the **precision**, the **recall**, and the **f1 score**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision:\", metrics.precision_score(y_test, y_pred,average='weighted'))\n",
    "print(\"recall:\", metrics.recall_score(y_test, y_pred,average='weighted'))\n",
    "print(\"f1 score:\", metrics.f1_score(y_test, y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since \"cultivate\" has three categories, we can see each of these metrics across its three values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that the overall correct classification rate is 51% (accuracy). \n",
    "\n",
    "While we only correctly identify 51% of the desired samples (recall), those that we properly labled to \"culitvate\"are 76% correct (precision)!  \n",
    "\n",
    "This is why you should make sure to carefully choose your metric when validating a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "# Checkpoint 4 of 5\n",
    "\n",
    "## Now you try!\n",
    "\n",
    "### Just like with checkpoint 3, re-create an SVM, but use the fruit dataset. \n",
    "### Calculate the accuracy and precision for the SVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## GridSearch and Cross-Folds\n",
    "\n",
    "Hyper-parameters are parameters that are not directly learnt within estimators. In scikit-learn they are passed as arguments in as parameters, like `K` in the KNN. \n",
    "\n",
    "Some models allow for specialized, efficient parameter search strategies. In other words, it'll find the best hyperparameter value for you! One function offered is called GridSearchCV, which exhaustively considers all parameter combinations. \n",
    "\n",
    "The grid search provided by `GridSearchCV` exhaustively generates potential values from a \"grid\" of parameter values (hence, `GridSearch`) specified with the param_grid parameter.\n",
    "\n",
    "First, let's import it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the `KNN` model from before. Here, you would use values to find the optimal number of n_neighbors. Let's look at values between 1 and 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': np.arange(1, 10)} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use `GridSearchCV` with the `KNN` model and find the optimal hyperparameters. \n",
    "\n",
    "\n",
    "The `Number_of_CrossFold_Validation` is the numbe of \"cross folds\" on the training data (e.g., 5, 10, 15, etc.). This is an important concept. \n",
    "\n",
    "\n",
    "\n",
    "## K-Folds Cross-Validation\n",
    "\n",
    "One of the first things you learn about in applying machine learning is the importance of cross-validation: evaluating the performance of your model on a portion of your dataset separate from what you used to train your model. The easiest way is to holdout a test set and compare performance using that. For instance, recall that when we split our data into testing and training sets, we did so using a 30%/70% split: train your model on 70% of your labeled data evaluate the trained model on the remaining 30%. \n",
    "\n",
    "K-fold cross-validation improves on this by letting you do this multiple times so you can see whether the test performance varies based on which samples you used to train and test. For instance, had we just used the 30% testing, our results may have been dependent (by chance) on whatever quirks were in that 30% hold out. If we use cross-validation and train our model on multiple training sets, we improve our model! \n",
    "\n",
    "This is what we refer to as the \"folds\" in our data, or the number of ways with which we split our data: It splits dataset into k consecutive folds.\n",
    "\n",
    "The example below shows a training set, with 10 folds: 9 are used for trainin and 1 is used for testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Machine learning](Images/10-k-fold-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this using `GridSearchCV`! Let's give it a try with a KNN. \n",
    "\n",
    "Recall the parameter grid we set for `K`. Now, let's also select the number of cross folds. Let's try 10. This will mirror the procedure we see above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_model_grid_search = GridSearchCV(knn, # Your Model \n",
    "                                    param_grid, # Your Parameters\n",
    "                                    cv=10) # Number of Crossfolds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit your data to the `GridSearch` you set up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_model_grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what value worked best!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_model_grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "# Checkpoint 5 of 5\n",
    "\n",
    "## Now you try!\n",
    "\n",
    "### Repeat the steps that we just walked through for the `KNN`, but now it with a CV of 5 and values from 1 to 5. How do your results change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
